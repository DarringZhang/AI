{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow多元线性回归\n",
    "\n",
    "## 波士顿房价预测\n",
    "\n",
    "### 北京信息科技大学大数据特长班2019《深度学习》实验课"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>目录<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\">\n",
    "    <ul class=\"toc-item\">\n",
    "        <li>\n",
    "            <span><a href=\"#Tensorflow实现多元线性回归\" data-toc-modified-id=\"Tensorflow实现多元线性回归\"><span class=\"toc-item-num\"></span>Tensorflow多元线性回归</a></span>\n",
    "            <ul class=\"toc-item\">\n",
    "                <li>\n",
    "                <span><a href=\"#1.载入数据\" data-toc-modified-id=\"1.载入数据\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>载入数据</a></span></li>\n",
    "                <li><span><a href=\"#2.构建模型\" data-toc-modified-id=\"2.构建模型\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>构建模型</a></span></li>\n",
    "                <li><span><a href=\"#3.训练模型\" data-toc-modified-id=\"3.训练模型\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>训练模型</a></span></li>\n",
    "                <li><span><a href=\"#4.测试模型\" data-toc-modified-id=\"4.测试模型\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>测试模型</a></span></li>\n",
    "                <li><span><a href=\"#5.可视化\" data-toc-modified-id=\"5.可视化\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>可视化</a></span></li>\n",
    "            </ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow多元线性回归\n",
    "\n",
    "### 本实验用波士顿房屋价格预测实例来进行多元线性回归学习。\n",
    "\n",
    "### 多元线性回归模型： y=w<sub>0</sub>+w<sub>1</sub>x<sub>1</sub>+w<sub>2</sub>x<sub>2</sub>+...+w<sub>d</sub>x<sub>d</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.载入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1.1导入相关库 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看Keras内置的数据集。keras内置数据集包括：boston_housing,cifar10,cifar100,mnist,fashion_mnist,imdb,reuters等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'boston_housing',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'fashion_mnist',\n",
       " 'imdb',\n",
       " 'mnist',\n",
       " 'reuters']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dir(keras.datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 数据集简介 **\n",
    "\n",
    "本实验使用波士顿房屋(boston_housing)数据集对房价数据进行回归分析，数据来自1970年代，波斯顿周边地区的房价，是用于机器学习的经典数据集。该数据集很小，共计506条数据，分为404个训练样本和102个测试样本。每条数据包含13个特征，分别为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** CRIM **：城镇人均犯罪率<br>\n",
    "** ZN **：住宅用地超过25000 sq.ft. 的比例<br>\n",
    "** INDUS ** : 城镇非零售商用土地的比例<br>\n",
    "** CHAS **：Charles河空变量（如果边界是河流，则为1；否则，为0）<br>\n",
    "** NOX **：一氧化氮浓度<br>\n",
    "** RM **：住宅平均房间数<br>\n",
    "**AGE **：1940年之前建成的自用房屋比例<br>\n",
    "** DIS **：到波士顿5个中心区域的加权距离<br>\n",
    "** RAD **：辐射性公路的靠近指数<br>\n",
    "** TAX **：每1万美元的全值财产税率<br>\n",
    "** PTRATIO **：城镇师生比例<br>\n",
    "** LSTAT **：人口中地位低下者的比例<br>\n",
    "** MEDV **：自住房的平均房价，单位：千美元<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1.2读取数据集 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import boston_housing\n",
    "#读取数据集，keras可以自动分割为训练集和测试集\n",
    "(train_data,train_targets),(test_data,test_targets)=boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以先查看一下数据集，以对其有个整体认识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_targets.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.23247e+00, 0.00000e+00, 8.14000e+00, 0.00000e+00, 5.38000e-01,\n",
       "        6.14200e+00, 9.17000e+01, 3.97690e+00, 4.00000e+00, 3.07000e+02,\n",
       "        2.10000e+01, 3.96900e+02, 1.87200e+01],\n",
       "       [2.17700e-02, 8.25000e+01, 2.03000e+00, 0.00000e+00, 4.15000e-01,\n",
       "        7.61000e+00, 1.57000e+01, 6.27000e+00, 2.00000e+00, 3.48000e+02,\n",
       "        1.47000e+01, 3.95380e+02, 3.11000e+00],\n",
       "       [4.89822e+00, 0.00000e+00, 1.81000e+01, 0.00000e+00, 6.31000e-01,\n",
       "        4.97000e+00, 1.00000e+02, 1.33250e+00, 2.40000e+01, 6.66000e+02,\n",
       "        2.02000e+01, 3.75520e+02, 3.26000e+00],\n",
       "       [3.96100e-02, 0.00000e+00, 5.19000e+00, 0.00000e+00, 5.15000e-01,\n",
       "        6.03700e+00, 3.45000e+01, 5.98530e+00, 5.00000e+00, 2.24000e+02,\n",
       "        2.02000e+01, 3.96900e+02, 8.01000e+00],\n",
       "       [3.69311e+00, 0.00000e+00, 1.81000e+01, 0.00000e+00, 7.13000e-01,\n",
       "        6.37600e+00, 8.84000e+01, 2.56710e+00, 2.40000e+01, 6.66000e+02,\n",
       "        2.02000e+01, 3.91430e+02, 1.46500e+01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.2, 42.3, 50. , 21.1, 17.7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1.3数据归一化：** <br>\n",
    "\n",
    "由于每个属性量纲不同，而且取值范围差异很大，直接进行回归会影响最终效果<br>\n",
    "因此，需要对数据进行归一化处理，使各个属性的数据都变换为[-1,1]之间的数据<br>\n",
    "常用的归一化的方法有Z-Score法和Min-Max法<br>\n",
    "** Z-Score法：**（X-Mean）/(Standard deviation)<br>\n",
    "** Min-Max法：**（X-Min）/(Max-Min)<br>\n",
    "\n",
    "本实验采用Z-Score方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练集各属性数据归一化\n",
    "mean = train_data.mean(axis=0)#计算平均值\n",
    "train_data -=mean#数据去均值\n",
    "std = train_data.std(axis=0)#计算标准差\n",
    "train_data/=std#归一化\n",
    "#测试集要用同样的方法进行归一化\n",
    "test_data-=mean\n",
    "test_data/=std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再查看一下归一化后的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.27224633, -0.48361547, -0.43576161, -0.25683275, -0.1652266 ,\n",
       "        -0.1764426 ,  0.81306188,  0.1166983 , -0.62624905, -0.59517003,\n",
       "         1.14850044,  0.44807713,  0.8252202 ],\n",
       "       [-0.40342651,  2.99178419, -1.33391162, -0.25683275, -1.21518188,\n",
       "         1.89434613, -1.91036058,  1.24758524, -0.85646254, -0.34843254,\n",
       "        -1.71818909,  0.43190599, -1.32920239],\n",
       "       [ 0.1249402 , -0.48361547,  1.0283258 , -0.25683275,  0.62864202,\n",
       "        -1.82968811,  1.11048828, -1.18743907,  1.67588577,  1.5652875 ,\n",
       "         0.78447637,  0.22061726, -1.30850006],\n",
       "       [-0.40149354, -0.48361547, -0.86940196, -0.25683275, -0.3615597 ,\n",
       "        -0.3245576 , -1.23667187,  1.10717989, -0.51114231, -1.094663  ,\n",
       "         0.78447637,  0.44807713, -0.65292624],\n",
       "       [-0.0056343 , -0.48361547,  1.0283258 , -0.25683275,  1.32861221,\n",
       "         0.15364225,  0.69480801, -0.57857203,  1.67588577,  1.5652875 ,\n",
       "         0.78447637,  0.3898823 ,  0.26349695]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.构建模型 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.1 定义$x$和$y$的占位符 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = tf.placeholder(tf.float32, [None,13], name = \"x\")\n",
    "y = tf.placeholder(tf.float32, [None,1], name = \"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.2 创建变量 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mona/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"Model\"):\n",
    "    w = tf.Variable(tf.random_normal([13,1],stddev=0.01),name=\"w\")\n",
    "    b = tf.Variable(1.,name=\"b\")\n",
    "    def model(x,w,b):\n",
    "        return tf.matmul(x,w) + b#矩阵乘法\n",
    "    pred=model(x,w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 命名空间name_scope ** <br>\n",
    "Tensorflow中常有数以千计节点，在可视化过程中很难一下子全部展示出来，因此可用name_scope为变量划分范围，在可视化中，这表示在计算图中的一个层级。<br>\n",
    "- name_scope** 不会影响 **用get_variable()创建的变量的名字<br>\n",
    "- name_scope** 会影响 **用Variable()创建的变量以及op_name<br>\n",
    "下面举例说明："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.训练模型 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.1 设置训练超参数 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs = 500 # 迭代次数\n",
    "learning_rate = 0.1 #学习率\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.2 定义均方差损失函数 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"LossFunction\"):\n",
    "    err=y-pred\n",
    "    err_2=tf.pow(err, 2)\n",
    "    loss_function = tf.reduce_mean(err_2) #均方根误差\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样，我们可以通过TensorBoard查看命名空间LossFunction下的操作（op），包括：mean, pow和sub(相减)，与我们定义的loss_function = tf.reduce_mean(tf.pow(y-pred, 2))相一致。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.3 选择优化器 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.4 声明会话 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()#初始化操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.5 生成图协议文件 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'log/boston/graph.pbtxt'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.write_graph(sess.graph, 'log/boston','graph.pbtxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_op = tf.summary.scalar(\"loss\", loss_function)#显示标量信息\n",
    "merged = tf.summary.merge_all()#所有summary全部保存到磁盘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过tf.summary.scalar( )记录loss_function的值，因此可在TensorBoard的SCALARS面板中查看到Loss值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.6 启动会话 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.7 创建摘要的文件写入符（FileWriter） **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = tf.summary.FileWriter('log/boston', sess.graph)#指定一个文件用来保存图。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.summary.FileWriter('/path/to/logs', sess.graph) 中所指定的路径‘/path/to/logs’，是运行tensorboard命令时参数logdir的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.8 迭代训练 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 542.3535\n",
      "1 528.6355\n",
      "2 516.44226\n",
      "3 505.7722\n",
      "4 496.57657\n",
      "5 488.73697\n",
      "6 482.0515\n",
      "7 476.2529\n",
      "8 471.0522\n",
      "9 466.18134\n",
      "10 461.4217\n",
      "11 456.61923\n",
      "12 451.6875\n",
      "13 446.59924\n",
      "14 441.37054\n",
      "15 436.04602\n",
      "16 430.68433\n",
      "17 425.34763\n",
      "18 420.0935\n",
      "19 414.96884\n",
      "20 410.00696\n",
      "21 405.22525\n",
      "22 400.62515\n",
      "23 396.19376\n",
      "24 391.90732\n",
      "25 387.73508\n",
      "26 383.6444\n",
      "27 379.60574\n",
      "28 375.596\n",
      "29 371.6011\n",
      "30 367.61658\n",
      "31 363.64636\n",
      "32 359.7007\n",
      "33 355.79327\n",
      "34 351.93817\n",
      "35 348.1472\n",
      "36 344.42834\n",
      "37 340.78455\n",
      "38 337.2135\n",
      "39 333.709\n",
      "40 330.26212\n",
      "41 326.8627\n",
      "42 323.50122\n",
      "43 320.1703\n",
      "44 316.86514\n",
      "45 313.58408\n",
      "46 310.3278\n",
      "47 307.09882\n",
      "48 303.9006\n",
      "49 300.7362\n",
      "50 297.60788\n",
      "51 294.51645\n",
      "52 291.46133\n",
      "53 288.44034\n",
      "54 285.45084\n",
      "55 282.48993\n",
      "56 279.55475\n",
      "57 276.64362\n",
      "58 273.7554\n",
      "59 270.8903\n",
      "60 268.04874\n",
      "61 265.23212\n",
      "62 262.44144\n",
      "63 259.6777\n",
      "64 256.94128\n",
      "65 254.23207\n",
      "66 251.54947\n",
      "67 248.89262\n",
      "68 246.26039\n",
      "69 243.65196\n",
      "70 241.06657\n",
      "71 238.50389\n",
      "72 235.96391\n",
      "73 233.44667\n",
      "74 230.9525\n",
      "75 228.4817\n",
      "76 226.03438\n",
      "77 223.6105\n",
      "78 221.2099\n",
      "79 218.83234\n",
      "80 216.47731\n",
      "81 214.14449\n",
      "82 211.8337\n",
      "83 209.54451\n",
      "84 207.27701\n",
      "85 205.03105\n",
      "86 202.8067\n",
      "87 200.60388\n",
      "88 198.42268\n",
      "89 196.26295\n",
      "90 194.12447\n",
      "91 192.00708\n",
      "92 189.91058\n",
      "93 187.83473\n",
      "94 185.77934\n",
      "95 183.74423\n",
      "96 181.72931\n",
      "97 179.73451\n",
      "98 177.75963\n",
      "99 175.80473\n",
      "100 173.86955\n",
      "101 171.95401\n",
      "102 170.05801\n",
      "103 168.1813\n",
      "104 166.32384\n",
      "105 164.48532\n",
      "106 162.66568\n",
      "107 160.86475\n",
      "108 159.08247\n",
      "109 157.31862\n",
      "110 155.57312\n",
      "111 153.84583\n",
      "112 152.13666\n",
      "113 150.44543\n",
      "114 148.772\n",
      "115 147.11621\n",
      "116 145.47798\n",
      "117 143.85712\n",
      "118 142.25352\n",
      "119 140.66704\n",
      "120 139.09756\n",
      "121 137.54497\n",
      "122 136.00908\n",
      "123 134.48985\n",
      "124 132.9871\n",
      "125 131.50073\n",
      "126 130.03058\n",
      "127 128.57652\n",
      "128 127.13844\n",
      "129 125.71621\n",
      "130 124.30969\n",
      "131 122.91878\n",
      "132 121.54334\n",
      "133 120.18327\n",
      "134 118.83843\n",
      "135 117.50865\n",
      "136 116.1939\n",
      "137 114.89399\n",
      "138 113.60883\n",
      "139 112.338295\n",
      "140 111.08222\n",
      "141 109.84055\n",
      "142 108.61311\n",
      "143 107.39984\n",
      "144 106.200554\n",
      "145 105.01516\n",
      "146 103.843575\n",
      "147 102.68565\n",
      "148 101.541245\n",
      "149 100.41027\n",
      "150 99.29262\n",
      "151 98.188156\n",
      "152 97.09679\n",
      "153 96.01837\n",
      "154 94.952805\n",
      "155 93.89999\n",
      "156 92.85978\n",
      "157 91.83211\n",
      "158 90.81681\n",
      "159 89.81383\n",
      "160 88.82302\n",
      "161 87.844284\n",
      "162 86.87752\n",
      "163 85.92257\n",
      "164 84.97938\n",
      "165 84.04782\n",
      "166 83.12778\n",
      "167 82.219185\n",
      "168 81.32187\n",
      "169 80.43577\n",
      "170 79.56077\n",
      "171 78.69675\n",
      "172 77.84365\n",
      "173 77.0013\n",
      "174 76.16964\n",
      "175 75.34857\n",
      "176 74.53798\n",
      "177 73.73774\n",
      "178 72.9478\n",
      "179 72.168015\n",
      "180 71.398315\n",
      "181 70.638596\n",
      "182 69.88873\n",
      "183 69.14866\n",
      "184 68.418236\n",
      "185 67.69742\n",
      "186 66.986084\n",
      "187 66.28412\n",
      "188 65.59146\n",
      "189 64.908\n",
      "190 64.23364\n",
      "191 63.56827\n",
      "192 62.911823\n",
      "193 62.2642\n",
      "194 61.62531\n",
      "195 60.995056\n",
      "196 60.37334\n",
      "197 59.760086\n",
      "198 59.15518\n",
      "199 58.558575\n",
      "200 57.970165\n",
      "201 57.38985\n",
      "202 56.817528\n",
      "203 56.253147\n",
      "204 55.69661\n",
      "205 55.14782\n",
      "206 54.606705\n",
      "207 54.07315\n",
      "208 53.547096\n",
      "209 53.028454\n",
      "210 52.517166\n",
      "211 52.01311\n",
      "212 51.516224\n",
      "213 51.026436\n",
      "214 50.543633\n",
      "215 50.067764\n",
      "216 49.59874\n",
      "217 49.136505\n",
      "218 48.680946\n",
      "219 48.232018\n",
      "220 47.789604\n",
      "221 47.35365\n",
      "222 46.924088\n",
      "223 46.50082\n",
      "224 46.083786\n",
      "225 45.672924\n",
      "226 45.268127\n",
      "227 44.869358\n",
      "228 44.476532\n",
      "229 44.08956\n",
      "230 43.708405\n",
      "231 43.33296\n",
      "232 42.963158\n",
      "233 42.59896\n",
      "234 42.24027\n",
      "235 41.88704\n",
      "236 41.539185\n",
      "237 41.196655\n",
      "238 40.859375\n",
      "239 40.527275\n",
      "240 40.200287\n",
      "241 39.878357\n",
      "242 39.561417\n",
      "243 39.24939\n",
      "244 38.94224\n",
      "245 38.63989\n",
      "246 38.342262\n",
      "247 38.049324\n",
      "248 37.760998\n",
      "249 37.477226\n",
      "250 37.197937\n",
      "251 36.923103\n",
      "252 36.652626\n",
      "253 36.386486\n",
      "254 36.1246\n",
      "255 35.866913\n",
      "256 35.613384\n",
      "257 35.36395\n",
      "258 35.11854\n",
      "259 34.87713\n",
      "260 34.639645\n",
      "261 34.406033\n",
      "262 34.176247\n",
      "263 33.95023\n",
      "264 33.727924\n",
      "265 33.509296\n",
      "266 33.294273\n",
      "267 33.082813\n",
      "268 32.874866\n",
      "269 32.67039\n",
      "270 32.46934\n",
      "271 32.27165\n",
      "272 32.077282\n",
      "273 31.886185\n",
      "274 31.698322\n",
      "275 31.513636\n",
      "276 31.332085\n",
      "277 31.153625\n",
      "278 30.978216\n",
      "279 30.805805\n",
      "280 30.636341\n",
      "281 30.469791\n",
      "282 30.306124\n",
      "283 30.145283\n",
      "284 29.987225\n",
      "285 29.83192\n",
      "286 29.67931\n",
      "287 29.529375\n",
      "288 29.382055\n",
      "289 29.237324\n",
      "290 29.095137\n",
      "291 28.955463\n",
      "292 28.818245\n",
      "293 28.683468\n",
      "294 28.55109\n",
      "295 28.421059\n",
      "296 28.29336\n",
      "297 28.167942\n",
      "298 28.044777\n",
      "299 27.92382\n",
      "300 27.80506\n",
      "301 27.688438\n",
      "302 27.573927\n",
      "303 27.461504\n",
      "304 27.351122\n",
      "305 27.242748\n",
      "306 27.136366\n",
      "307 27.03193\n",
      "308 26.929426\n",
      "309 26.828802\n",
      "310 26.730038\n",
      "311 26.633102\n",
      "312 26.537962\n",
      "313 26.444601\n",
      "314 26.352983\n",
      "315 26.26307\n",
      "316 26.174843\n",
      "317 26.088278\n",
      "318 26.003344\n",
      "319 25.92001\n",
      "320 25.838255\n",
      "321 25.758045\n",
      "322 25.67936\n",
      "323 25.60218\n",
      "324 25.52647\n",
      "325 25.452215\n",
      "326 25.37938\n",
      "327 25.307936\n",
      "328 25.23789\n",
      "329 25.169182\n",
      "330 25.101807\n",
      "331 25.035742\n",
      "332 24.970959\n",
      "333 24.907442\n",
      "334 24.845167\n",
      "335 24.784107\n",
      "336 24.724249\n",
      "337 24.66557\n",
      "338 24.608044\n",
      "339 24.551657\n",
      "340 24.49639\n",
      "341 24.442213\n",
      "342 24.389118\n",
      "343 24.337088\n",
      "344 24.28609\n",
      "345 24.236118\n",
      "346 24.187153\n",
      "347 24.139166\n",
      "348 24.09215\n",
      "349 24.046078\n",
      "350 24.000946\n",
      "351 23.956726\n",
      "352 23.913404\n",
      "353 23.870964\n",
      "354 23.829391\n",
      "355 23.788675\n",
      "356 23.748795\n",
      "357 23.709734\n",
      "358 23.671469\n",
      "359 23.634003\n",
      "360 23.597305\n",
      "361 23.561377\n",
      "362 23.526184\n",
      "363 23.491734\n",
      "364 23.457996\n",
      "365 23.424969\n",
      "366 23.392632\n",
      "367 23.36097\n",
      "368 23.32998\n",
      "369 23.299644\n",
      "370 23.269941\n",
      "371 23.240875\n",
      "372 23.212431\n",
      "373 23.184578\n",
      "374 23.15733\n",
      "375 23.130661\n",
      "376 23.104559\n",
      "377 23.079021\n",
      "378 23.05403\n",
      "379 23.029572\n",
      "380 23.005646\n",
      "381 22.982244\n",
      "382 22.959347\n",
      "383 22.936934\n",
      "384 22.91502\n",
      "385 22.89358\n",
      "386 22.872606\n",
      "387 22.852097\n",
      "388 22.832043\n",
      "389 22.812418\n",
      "390 22.79323\n",
      "391 22.774467\n",
      "392 22.756115\n",
      "393 22.738173\n",
      "394 22.720629\n",
      "395 22.703472\n",
      "396 22.6867\n",
      "397 22.6703\n",
      "398 22.654268\n",
      "399 22.638597\n",
      "400 22.623274\n",
      "401 22.608297\n",
      "402 22.59366\n",
      "403 22.579353\n",
      "404 22.565372\n",
      "405 22.551702\n",
      "406 22.538347\n",
      "407 22.5253\n",
      "408 22.512548\n",
      "409 22.500082\n",
      "410 22.487904\n",
      "411 22.476007\n",
      "412 22.464384\n",
      "413 22.453024\n",
      "414 22.44193\n",
      "415 22.43109\n",
      "416 22.420507\n",
      "417 22.410166\n",
      "418 22.400066\n",
      "419 22.3902\n",
      "420 22.380564\n",
      "421 22.371157\n",
      "422 22.361963\n",
      "423 22.352991\n",
      "424 22.344229\n",
      "425 22.335669\n",
      "426 22.32732\n",
      "427 22.319162\n",
      "428 22.311197\n",
      "429 22.303421\n",
      "430 22.295835\n",
      "431 22.288424\n",
      "432 22.281197\n",
      "433 22.274136\n",
      "434 22.267242\n",
      "435 22.260523\n",
      "436 22.25396\n",
      "437 22.247557\n",
      "438 22.2413\n",
      "439 22.2352\n",
      "440 22.229254\n",
      "441 22.223442\n",
      "442 22.21778\n",
      "443 22.212252\n",
      "444 22.206858\n",
      "445 22.201595\n",
      "446 22.196463\n",
      "447 22.191462\n",
      "448 22.186579\n",
      "449 22.18182\n",
      "450 22.177166\n",
      "451 22.172636\n",
      "452 22.16822\n",
      "453 22.16391\n",
      "454 22.159704\n",
      "455 22.155607\n",
      "456 22.151613\n",
      "457 22.147717\n",
      "458 22.143923\n",
      "459 22.140215\n",
      "460 22.136608\n",
      "461 22.133087\n",
      "462 22.129656\n",
      "463 22.126312\n",
      "464 22.123049\n",
      "465 22.119875\n",
      "466 22.116777\n",
      "467 22.113758\n",
      "468 22.110815\n",
      "469 22.107952\n",
      "470 22.10516\n",
      "471 22.102436\n",
      "472 22.099787\n",
      "473 22.097202\n",
      "474 22.094683\n",
      "475 22.092232\n",
      "476 22.089842\n",
      "477 22.087513\n",
      "478 22.085249\n",
      "479 22.083038\n",
      "480 22.08089\n",
      "481 22.078793\n",
      "482 22.07675\n",
      "483 22.074762\n",
      "484 22.072826\n",
      "485 22.070946\n",
      "486 22.069109\n",
      "487 22.067318\n",
      "488 22.065582\n",
      "489 22.063885\n",
      "490 22.062237\n",
      "491 22.060635\n",
      "492 22.059063\n",
      "493 22.057547\n",
      "494 22.05606\n",
      "495 22.054623\n",
      "496 22.053217\n",
      "497 22.051855\n",
      "498 22.050526\n",
      "499 22.049229\n"
     ]
    }
   ],
   "source": [
    "loss_list = []   #用于保存loss值的列表\n",
    "for epoch in range (train_epochs):\n",
    "    ys=train_targets.reshape(404,1)#重新调整矩阵的行数、列数、维数;将一维数组变成二维数组\n",
    "    _,summary_str,lossv=sess.run([optimizer,loss_op,loss_function],#优化器，误差的标量信息，均方根误差\n",
    "                                 feed_dict={x: train_data, y: ys})     \n",
    "    writer.add_summary(summary_str, epoch)#将这些卸入文件中    \n",
    "    loss_list.append(lossv)     #每步添加一次\n",
    "    xvalues, yvalues = shuffle(train_data, train_targets)\n",
    "    print (epoch,lossv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.9 训练的简单可视化 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.10 查看学习到的多元线性回归模型系数 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.18728\n",
      "[[-1.1073202 ]\n",
      " [ 1.3526922 ]\n",
      " [ 0.02607783]\n",
      " [ 0.9945241 ]\n",
      " [-2.4015353 ]\n",
      " [ 2.3965657 ]\n",
      " [ 0.21086183]\n",
      " [-3.4714723 ]\n",
      " [ 2.904751  ]\n",
      " [-1.9536452 ]\n",
      " [-1.9828655 ]\n",
      " [ 0.8195087 ]\n",
      " [-4.027182  ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "b_hat=b.eval(session=sess)\n",
    "w_hat=w.eval(session=sess)\n",
    "print(b_hat)\n",
    "print(w_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.测试模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把测试集feed进模型中，运行后查看平均预测误差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集上平均预测误差为： 23.21593\n"
     ]
    }
   ],
   "source": [
    "y_test=test_targets.reshape(102,1)\n",
    "lossv=sess.run(loss_function, feed_dict={x: test_data, y: y_test})     \n",
    "print(\"测试集上平均预测误差为：\",lossv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5.1 启动TensorBoard **<br>\n",
    "\n",
    "在Anaconda Prompt中运行TensorBoard，并将日志的地址指向程序日志输出的地址\n",
    "\n",
    "命令：tensorboard --logdir=/path/log\n",
    "\n",
    "** 5.2 访问TensorBoard **<br>\n",
    "\n",
    "浏览器访问网址\n",
    "\n",
    "http://localhost:6006\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "目录",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
